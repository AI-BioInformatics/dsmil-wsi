{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import mil_dsmil_softmax as mil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import os, glob\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision import transforms, utils\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES']='0'\n",
    "use_cuda = torch.cuda.is_available()\n",
    "if use_cuda:\n",
    "    torch.cuda.set_device(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace()\n",
    "args.num_classes = 2\n",
    "args.num_feats = 512\n",
    "args.num_epochs = 90\n",
    "args.batch_size = 400\n",
    "args.num_workers = 4\n",
    "args.top_k = 8\n",
    "args.lr = 0.0001\n",
    "args.patch_size = 224\n",
    "args.img_channel = 3\n",
    "# args.class_weights = [1, 1, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FCLayer(nn.Module):\n",
    "    def __init__(self, in_size, out_size=1):\n",
    "        super(FCLayer, self).__init__()\n",
    "        self.fc = nn.Sequential(nn.Linear(in_size, out_size))\n",
    "    def forward(self, feats):\n",
    "        x = self.fc(feats)\n",
    "        return feats, x\n",
    "i_classifier = FCLayer(in_size=args.num_feats, out_size=args.num_classes).cuda()\n",
    "b_classifier = mil.BClassifier(input_size=args.num_feats, output_class=args.num_classes).cuda()\n",
    "\n",
    "# gpu_ids = [0, 1, 2, 3, 4, 5]\n",
    "# torch.cuda.set_device(gpu_ids[0])\n",
    "# i_classifier = torch.nn.DataParallel(i_classifier, device_ids=gpu_ids).cuda()\n",
    "\n",
    "milnet = mil.MILNet(i_classifier, b_classifier).cuda()\n",
    "print(milnet)\n",
    "criterion = nn.BCEWithLogitsLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# state_dict = torch.load('tcga-ds-feats-simclr-10x.pth')\n",
    "# milnet.load_state_dict(state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bag_feats(csv_file_df):\n",
    "    feats_csv_path = 'data_feats_simclr_10x/' + csv_file_df.iloc[0].split('/')[1] + '.csv'\n",
    "    df = pd.read_csv(feats_csv_path)\n",
    "    feats = shuffle(df).reset_index(drop=True)\n",
    "    feats = feats.to_numpy()\n",
    "    label = np.zeros(args.num_classes)\n",
    "    label[int(csv_file_df.iloc[1])] = 1\n",
    "    return label, feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_df):\n",
    "    csvs = shuffle(train_df).reset_index(drop=True)\n",
    "    total_loss = 0\n",
    "    bc = 0\n",
    "    for i in range(len(train_df)):\n",
    "        optimizer.zero_grad()\n",
    "        label, feats = get_bag_feats(train_df.iloc[i])\n",
    "        bag_label = Variable(Tensor([label]))\n",
    "        bag_feats = Variable(Tensor([feats]))\n",
    "        bag_feats = bag_feats.view(-1, args.num_feats)\n",
    "        ins_prediction, bag_prediction, _, _ = milnet(bag_feats)\n",
    "        max_prediction, _ = torch.max(ins_prediction, 0)        \n",
    "        bag_loss = criterion(bag_prediction.view(1, -1), bag_label.view(1, -1))\n",
    "        max_loss = criterion(max_prediction.view(1, -1), bag_label.view(1, -1))\n",
    "        loss = 0.5*bag_loss + 0.5*max_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss = total_loss + loss.item()\n",
    "        sys.stdout.write('\\r[%d/%d] bag loss: %.4f, %.4f' % (i, len(train_df), max_loss.item(), bag_loss.item()))\n",
    "    return total_loss / len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(test_df):\n",
    "    csvs = shuffle(test_df).reset_index(drop=True)\n",
    "    total_loss = 0\n",
    "    test_labels = []\n",
    "    test_predictions = []\n",
    "    with torch.no_grad():\n",
    "        for i in range(len(test_df)):\n",
    "            label, feats = get_bag_feats(test_df.iloc[i])\n",
    "            bag_label = Variable(Tensor([label]))\n",
    "            bag_feats = Variable(Tensor([feats]))\n",
    "            bag_feats = bag_feats.view(-1, args.num_feats)\n",
    "            ins_prediction, bag_prediction, _, _ = milnet(bag_feats)\n",
    "            max_prediction, _ = torch.max(ins_prediction, 0)  \n",
    "            bag_loss = criterion(bag_prediction.view(1, -1), bag_label.view(1, -1))\n",
    "            max_loss = criterion(max_prediction.view(1, -1), bag_label.view(1, -1))\n",
    "            loss = 0.5*bag_loss + 0.5*max_loss\n",
    "            total_loss = total_loss + loss.item()\n",
    "            sys.stdout.write('\\r[%d/%d] bag loss: %.4f, %.4f' % (i, len(test_df), max_loss.item(), bag_loss.item()))\n",
    "            test_labels.extend([label])\n",
    "            test_predictions.extend([(0.0*torch.sigmoid(max_prediction)+1.0*torch.sigmoid(bag_prediction)).squeeze().cpu().numpy()])\n",
    "    test_labels = np.array(test_labels)\n",
    "    test_predictions = np.array(test_predictions)\n",
    "    auc_value, _, thresholds_optimal = multi_label_roc(test_labels, test_predictions, args.num_classes, pos_label=1)\n",
    "    for i in range(args.num_classes):\n",
    "        class_prediction_bag = test_predictions[:, i]\n",
    "        class_prediction_bag[class_prediction_bag>=thresholds_optimal[i]] = 1\n",
    "        class_prediction_bag[class_prediction_bag<thresholds_optimal[i]] = 0\n",
    "        test_predictions[:, i] = class_prediction_bag\n",
    "    bag_score = 0\n",
    "    for i in range(0, len(test_df)):\n",
    "        bag_score = np.array_equal(test_labels[i], test_predictions[i]) + bag_score         \n",
    "    avg_score = bag_score / len(test_df)\n",
    "    \n",
    "    return total_loss / len(test_df), avg_score, auc_value, thresholds_optimal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_label_roc(labels, predictions, num_classes, pos_label=1):\n",
    "    fprs = []\n",
    "    tprs = []\n",
    "    thresholds = []\n",
    "    thresholds_optimal = []\n",
    "    aucs = []\n",
    "    for c in range(0, num_classes):\n",
    "        label = labels[:, c]\n",
    "        prediction = predictions[:, c]\n",
    "        fpr, tpr, threshold = roc_curve(label, prediction, pos_label=1)\n",
    "        fpr_optimal, tpr_optimal, threshold_optimal = optimal_thresh(fpr, tpr, threshold)\n",
    "        c_auc = roc_auc_score(label, prediction)\n",
    "        aucs.append(c_auc)\n",
    "        thresholds.append(threshold)\n",
    "        thresholds_optimal.append(threshold_optimal)\n",
    "    return aucs, thresholds, thresholds_optimal\n",
    "\n",
    "def optimal_thresh(fpr, tpr, thresholds, p=0):\n",
    "    loss = (fpr - tpr) - p * tpr / (fpr + tpr + 1)\n",
    "    idx = np.argmin(loss, axis=0)\n",
    "    return fpr[idx], tpr[idx], thresholds[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "runs = 'logs/tcga-ds-feats-simclr-10x'\n",
    "writer = SummaryWriter(runs)\n",
    "optimal_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(milnet.parameters(), lr=0.0001, betas=(0.5, 0.9), weight_decay=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(milnet.parameters(), lr=args.lr, momentum=0.9, weight_decay=5e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bags_LUAD_path = pd.read_csv('LUAD.csv')\n",
    "bags_LUSC_path = pd.read_csv('LUSC.csv')\n",
    "cut_LUAD = int(len(bags_LUAD_path)*0.8)\n",
    "cut_LUSC = int(len(bags_LUSC_path)*0.8)\n",
    "train_bags_LUAD_path = bags_LUAD_path.iloc[0:cut_LUAD, :]\n",
    "train_bags_LUSC_path = bags_LUSC_path.iloc[0:cut_LUSC, :]\n",
    "test_bags_LUAD_path = bags_LUAD_path.iloc[cut_LUAD:, :]\n",
    "test_bags_LUSC_path = bags_LUSC_path.iloc[cut_LUSC:, :]\n",
    "Tensor = torch.cuda.FloatTensor\n",
    "for epoch in range(1, 1000):\n",
    "    train_path = shuffle(train_bags_LUAD_path.append(train_bags_LUSC_path)).reset_index(drop=True)\n",
    "    test_path = shuffle(test_bags_LUAD_path.append(test_bags_LUSC_path)).reset_index(drop=True)\n",
    "    train_loss_bag = train(train_path) # iterate all bags\n",
    "    test_loss_bag, avg_score, aucs, thresholds_optimal = test(test_path)\n",
    "    print('\\r Epoch [%d/%d] train loss: %.4f, test loss: %.4f, average score: %.4f, auc_LUAD: %.4f, auc_LUSC: %.4f' % \n",
    "          (epoch, args.num_epochs, train_loss_bag, test_loss_bag, avg_score, aucs[0], aucs[1]))\n",
    "    print(thresholds_optimal)\n",
    "    writer.add_scalar(runs+'/loss/train', train_loss_bag, epoch)\n",
    "    writer.add_scalar(runs+'/loss/test', test_loss_bag, epoch)\n",
    "    writer.add_scalar(runs+'/score', avg_score, epoch)\n",
    "    writer.add_scalar(runs+'/auc_LUAD', aucs[0], epoch)\n",
    "    writer.add_scalar(runs+'/auc_LUSC', aucs[1], epoch)\n",
    "    current_score = avg_score\n",
    "    if optimal_score < current_score:\n",
    "        optimal_score = current_score\n",
    "        torch.save(milnet.state_dict(), 'tcga-ds-feats-simclr.pth')\n",
    "        print('saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
