{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.models as models\n",
    "import dsmil as mil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import sys\n",
    "import argparse\n",
    "import os\n",
    "import glob\n",
    "import pandas as pd\n",
    "import csv\n",
    "import numpy as np\n",
    "import random\n",
    "import math\n",
    "from skimage import io, img_as_float\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, accuracy_score\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import OrderedDict\n",
    "\n",
    "import torchvision.transforms.functional as VF\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = argparse.Namespace()\n",
    "args.num_classes = 2\n",
    "args.num_feats = 512\n",
    "args.num_epochs = 90\n",
    "args.batch_size = 128\n",
    "args.num_workers = 0\n",
    "args.top_k = 8\n",
    "args.lr = 0.0001\n",
    "args.patch_size = 224\n",
    "args.img_channel = 3\n",
    "args.dataset = 'wsi-tcga-lung'\n",
    "args.backbone = 'resnet18'\n",
    "args.magnification = '20x'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if args.backbone == 'resnet18':\n",
    "    resnet = models.resnet18(pretrained=False, norm_layer=nn.InstanceNorm2d)\n",
    "    num_feats = 512\n",
    "if args.backbone == 'resnet34':\n",
    "    resnet = models.resnet34(pretrained=False, norm_layer=nn.InstanceNorm2d)\n",
    "    num_feats = 512\n",
    "if args.backbone == 'resnet50':\n",
    "    resnet = models.resnet50(pretrained=False, norm_layer=nn.InstanceNorm2d)\n",
    "    num_feats = 2048\n",
    "if args.backbone == 'resnet101':\n",
    "    resnet = models.resnet101(pretrained=False, norm_layer=nn.InstanceNorm2d)\n",
    "    num_feats = 2048\n",
    "for param in resnet.parameters():\n",
    "    param.requires_grad = False\n",
    "resnet.fc = nn.Identity()\n",
    "i_classifier = mil.IClassifier(resnet, num_feats, output_class=args.num_classes).cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "_IncompatibleKeys(missing_keys=['fc.weight', 'fc.bias'], unexpected_keys=[])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_path = glob.glob('simclr/runs/*/checkpoints/*.pth')[-1]\n",
    "state_dict_weights = torch.load(weight_path)\n",
    "try:\n",
    "    state_dict_weights.pop('module.l1.weight')\n",
    "    state_dict_weights.pop('module.l1.bias')\n",
    "    state_dict_weights.pop('module.l2.weight')\n",
    "    state_dict_weights.pop('module.l2.bias')\n",
    "except:\n",
    "    state_dict_weights.pop('l1.weight')\n",
    "    state_dict_weights.pop('l1.bias')\n",
    "    state_dict_weights.pop('l2.weight')\n",
    "    state_dict_weights.pop('l2.bias')\n",
    "state_dict_init = i_classifier.state_dict()\n",
    "new_state_dict = OrderedDict()\n",
    "for (k, v), (k_0, v_0) in zip(state_dict_weights.items(), state_dict_init.items()):\n",
    "    name = k_0\n",
    "    new_state_dict[name] = v\n",
    "i_classifier.load_state_dict(new_state_dict, strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BagDataset():\n",
    "    def __init__(self, csv_file, transform=None):\n",
    "        self.files_list = csv_file\n",
    "        self.transform = transform\n",
    "    def __len__(self):\n",
    "        return len(self.files_list)\n",
    "    def __getitem__(self, idx):\n",
    "        temp_path = self.files_list[idx]\n",
    "        img = os.path.join(temp_path)\n",
    "        img = Image.open(img)\n",
    "        sample = {'input': img}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        return sample \n",
    "\n",
    "class ToTensor(object):\n",
    "    def __call__(self, sample):\n",
    "        img = sample['input']\n",
    "        img = VF.to_tensor(img)\n",
    "        return {'input': img} \n",
    "    \n",
    "class Compose(object):\n",
    "    def __init__(self, transforms):\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __call__(self, img):\n",
    "        for t in self.transforms:\n",
    "            img = t(img)\n",
    "        return img\n",
    "\n",
    "def bag_dataset(csv_file_path):\n",
    "    transformed_dataset = BagDataset(csv_file=csv_file_path,\n",
    "                                    transform=Compose([\n",
    "                                        ToTensor()\n",
    "                                    ]))\n",
    "    dataloader = DataLoader(transformed_dataset, batch_size=args.batch_size, shuffle=True, num_workers=args.num_workers, drop_last=False)\n",
    "    return dataloader, len(transformed_dataset)\n",
    "\n",
    "def compute_feats(bags_list, save_path=None):\n",
    "    num_bags = len(bags_list)\n",
    "    Tensor = torch.FloatTensor\n",
    "    for i in range(0, num_bags):\n",
    "        feats_list = []\n",
    "        if args.magnification == '20x':\n",
    "            csv_file_path = glob.glob(os.path.join(bags_list[i], '*/*.jpg'))\n",
    "        else:\n",
    "            csv_file_path = glob.glob(os.path.join(bags_list[i], '*.jpg'))\n",
    "        print(len(csv_file_path))\n",
    "        dataloader, bag_size = bag_dataset(csv_file_path)\n",
    "        with torch.no_grad():\n",
    "            for iteration, batch in enumerate(dataloader):\n",
    "                patches = batch['input'].float().cuda() \n",
    "                feats, classes = i_classifier(patches)\n",
    "                feats = feats.cpu().numpy()\n",
    "                feats_list.extend(feats)\n",
    "        df = pd.DataFrame(feats_list)\n",
    "        os.makedirs(os.path.join(save_path, bags_list[i].split(os.path.sep)[-3]), exist_ok=True)\n",
    "        df.to_csv(os.path.join(save_path, bags_list[i].split(os.path.sep)[-3], bags_list[i].split(os.path.sep)[-2]+'.csv'), index=False, float_format='%.4f')\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5667\n",
      "0\n",
      "6181\n",
      "1\n",
      "5991\n",
      "2\n",
      "25254\n",
      "3\n",
      "9857\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "if args.dataset == 'wsi-tcga-lung':\n",
    "    bags_path = os.path.join('WSI', 'TCGA-lung', 'pyramid', '*', '*')\n",
    "feats_path = os.path.join('datasets', args.dataset)\n",
    "os.makedirs(feats_path, exist_ok=True)\n",
    "bags_list = glob.glob(bags_path+os.path.sep)\n",
    "compute_feats(bags_list, feats_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
